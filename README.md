# Computer-Vision-using-Deep-Learning-Model
Vision Transformer-
The Vision Transformer (ViT) is a deep learning model that applies the Transformer architecture—originally developed for natural language processing—to image recognition tasks. Instead of using convolutional layers like traditional convolutional neural networks (CNNs), ViT splits an image into fixed-size patches, flattens them, and processes them as a sequence of tokens, similar to words in a sentence. These patch embeddings are then passed through Transformer layers, allowing the model to capture long-range dependencies and global context more effectively. ViT has shown competitive or superior performance to CNNs on large-scale image datasets, especially when trained with extensive data and computational resources, marking a significant shift in computer vision research.

DATASET- MNIST DATASET

![WhatsApp Image 2025-07-07 at 23 16 35_eb310e13](https://github.com/user-attachments/assets/28291d8f-efec-427d-825d-67208c75a289)
